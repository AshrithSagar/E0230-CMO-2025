\section*{Question 1: Local vs Global Convergence}

Consider the function
\begin{equation*}
    f(x) = x^{3}-2 x+2
\end{equation*}

\begin{enumerate}
    \item Write down \( f^{\prime}(x) \) and \( f^{\prime \prime}(x) \).

    \item Apply Newton's method starting from \( x_{0} = 0 \) and compute the first two iterates.

    \item Repeat starting from \( x_{0} = -2 \).

    \item Compare the two behaviours.
        Why does Newton's method converge rapidly in one case but not in the other?
        What does this illustrate about the importance of the starting point?
\end{enumerate}

\subsection*{Solution}

\vspace{-1em}
\subsection*{(1) \( f'(x), f''(x) \)}

\vspace{-2em}
\begin{align*}
    \implies
    f'(x)
    & =
    3 x^2 - 2
    \\
    f''(x)
    & =
    6 x
\end{align*}

\vspace{-2.5em}
\subsection*{(2) Newton's method, \( x_0 = 0 \)}

\vspace{-1em}
\begin{equation*}
    x_{n+1}
    =
    x_n - \frac{f'(x_n)}{f''(x_n)}
\end{equation*}
\vspace{-1em}
\begin{align*}
    \implies
    x_1
    & =
    0 - \frac{-2}{0}
    \implies
    \boxed{
        x_1
        =
        \text{undefined}
    }
    \\
    \implies
    &
    \boxed{
        x_2
        =
        \text{undefined}
    }
\end{align*}

\vspace{-2.5em}
\subsection*{(3) Newton's method, \( x_0 = -2 \)}

\vspace{-1em}
\begin{align*}
    \implies
    x_1
    & =
    -2 - \frac{10}{-12}
    \implies
    \boxed{
        x_1
        =
        \frac{-7}{6}
    }
    \\
    \implies
    x_2
    & =
    \frac{-7}{6} - \frac{\frac{49}{12} - 2}{-7}
    =
    \frac{-7}{6} - \frac{25}{-7 \times 12}
    =
    \frac{-7}{6} + \frac{25}{84}
    =
    \frac{-438}{504}
    \implies
    \boxed{
        x_2
        =
        \frac{-217}{252}
    }
\end{align*}

\vspace{-2.5em}
\subsection*{(4) Comparison}

\vspace{-0.5em}
In the first case, starting from \( x_0 = 0 \), we find that \( f''(x_0) = 0 \).
This makes the Newton's method update undefined, and hence we cannot proceed with the iterations.
This illustrates that Newton's method can \underline{fail to converge} if the starting point is at a location where the second derivative is zero or very small.
In the second case, starting from \( x_0 = -2 \), we find that the iterations proceed without any issues, and we obtain valid updates for \( x_1 \) and \( x_2 \).
This shows that the choice of \underline{starting point is crucial for the convergence} of Newton's method.
