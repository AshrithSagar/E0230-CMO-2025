
\part{Constrained optimisation}

\chapter{Introduction}

\section{Constrained optimisation problem}

A \textbf{constrained minimisation problem} aims to find a point \( \xstar \in \calC \) that minimises a function \( f: \calD \subseteq \R^d \to \R \), i.e.,
\vspace{-1.5em}
\begin{align*}
    &
    \minimize_{\x \in \calC} \func{f}{\x}
    \\
    \func{f}{\xstar}
    =
    \min_{\x \in \calC} \func{f}{\x}
    \quad \iff \quad
    \xstar
    & =
    \argmin_{\x \in \calC} \func{f}{\x}
    \quad \iff \quad
    \func{f}{\xstar}
    \leq
    \func{f}{\x},
    \quad \forall \x \in \calC
\end{align*}

The set \( \calC \subseteq \calD \) is called the \textbf{feasible region} / \textbf{feasible set} / \textbf{solution space}.

If \( f \) is unbounded below on \( \calC \), then the problem is said to be \textbf{unbounded}.

If \( \calC = \emptyset \), then the problem is said to be \textbf{infeasible}.

\section{Types of minimum}

\subsection{Global minimum}

\begin{definition}{Global minimum}{global-minimum-constrained}
    The point \( \xstar \in \calC \subseteq \calD \) is a \textbf{global minimum} of the function \( f: \calD \subseteq \R^d \to \R \) if
    \vspace{-0.5em}
    \begin{equation*}
        \func{f}{\xstar} \leq \func{f}{\x},
        \quad \forall \x \in \calC
    \end{equation*}
\end{definition}

\subsection{Strict global minimum}

\begin{definition}{Strict global minimum}{}
    The point \( \xstar \in \calC \subseteq \calD \) is a \textbf{strict global minimum} of the function \( f: \calD \subseteq \R^d \to \R \) if
    \vspace{-0.5em}
    \begin{equation*}
        \func{f}{\xstar} < \func{f}{\x},
        \quad \forall \x \in \calC \setminus \set{\xstar}
    \end{equation*}
\end{definition}

\subsection{Local minimum}

\begin{definition}{Local minimum}{local-minimum-constrained}
    The point \( \xstar \in \calC \subseteq \calD \) is a \textbf{local minimum} of the function \( f: \calD \subseteq \R^d \to \R \) if there exists a \( \delta > 0 \) such that for all \( \x \in \calC \) in the \( \delta \)-neighborhood of \( \xstar \), we have \( \func{f}{\xstar} \leq \func{f}{\x} \), i.e.,
    \vspace{-0.5em}
    \begin{equation*}
        \func{f}{\xstar} \leq \func{f}{\x},
        \quad \forall \x \in \calC \cap B_{\delta}(\xstar)
    \end{equation*}
\end{definition}

\begin{definition}{Strict local minimum}{}
    The point \( \xstar \in \calC \subseteq \calD \) is a \textbf{strict local minimum} of the function \( f: \calD \subseteq \R^d \to \R \) if there exists a \( \delta > 0 \) such that for all \( \x \in \calC \) in the \( \delta \)-neighborhood of \( \xstar \) except \( \xstar \) itself, we have \( \func{f}{\xstar} < \func{f}{\x} \), i.e.,
    \vspace{-0.5em}
    \begin{equation*}
        \func{f}{\xstar} < \func{f}{\x},
        \quad \forall \x \in \calC \cap B_{\delta}(\xstar) \setminus \set{\xstar}
    \end{equation*}
\end{definition}

\section{Projection onto a convex set}

\begin{definition}{Projection onto a convex set}{}
    The \textbf{projection} \( P_{\calC}: \R^d \to \calC \) of a point \( \x \in \R^d \) onto a non-empty, closed, convex set \( \calC \subseteq \R^d \) is defined as
    \vspace{-0.5em}
    \begin{equation*}
        \func{P_{\calC}}{\x}
        \triangleq
        \argmin_{\z \in \calC}
        \half \norm{\x - \z}^2
    \end{equation*}
\end{definition}

From the definition, we can see that the following holds true:
\begin{itemize}
    \item The projection always exists since \( \calC \) is non-empty and closed.

    \item The projection is unique since \( \calC \) is convex.

    \item \( \func{P_{\calC}}{\x} \in \calC, \; \forall \x \in \R^d \).

    \item \( \func{P_{\calC}}{\x} \) is the point in \( \calC \) closest to \( \x \).

    \item \( \func{P_{\calC}}{\x} = \x, \; \forall \x \in \calC \).
\end{itemize}

\begin{theorem}{Characterisation of projection onto a convex set}{projection-characterisation}
    Let \( \calC \subseteq \R^d \) be a non-empty, closed, convex set.
    The projection \( \func{P_{\calC}}{\x} \) exists and is unique for any \( \x \in \R^d \).
    Furthermore, \( \z = \func{P_{\calC}}{\x} \) if and only if \( \dotp{\pbrac{\x - \z}}{\pbrac{\y - \z}} \leq 0, \; \forall \y \in \calC \).
\end{theorem}

\begin{proof}
    Let \( \z = \func{P_{\calC}}{\x} \).
    Since \( \calC \) is non-empty and closed, the projection exists.
    Since \( \calC \) is convex, the projection is unique.

    For any \( \y \in \calC, \; t \in (0, 1) \), we have \( \z + t(\y - \z) \in \calC \).
    Thus,
    \begin{align*}
        &
        \half \norm{\x - \z}^2
        \leq
        \half \norm{\x - (\z + t(\y - \z))}^2
        =
        \half \norm{(\x - \z) - t(\y - \z)}^2
        \\ &
        0
        \leq
        -2t\dotp{\pbrac{\x - \z}}{\pbrac{\y - \z}} + t^2\norm{\y - \z}^2
    \end{align*}
    Dividing by \( t > 0 \) and letting \( t \to 0^+ \), we get \( 0 \leq -2\dotp{\pbrac{\x - \z}}{\pbrac{\y - \z}} \), i.e., \( \dotp{\pbrac{\x - \z}}{\pbrac{\y - \z}} \leq 0, \; \forall \y \in \calC. \)
\end{proof}

\section{Separating hyperplane theorem}

\begin{theorem}{Separating hyperplane theorem}{separating-hyperplane-theorem}
    Let \( \calC, \calD \subseteq \R^d \) be non-empty, disjoint, closed, convex sets.
    If one of the sets is compact, then there exists a hyperplane that separates them.
    That is, there exists \( \b \in \R^d \setminus \set{\zero}, \; c \in \R \) such that
    \vspace{-0.5em}
    \begin{equation*}
        \dotp{\b}{\x}
        \leq c
        <
        \dotp{\b}{\y},
        \quad
        \forall \x \in \calC,
        \; \forall \y \in \calD
    \end{equation*}
\end{theorem}

\begin{proof}
    Since one of the sets is compact, there exists \( \x_0 \in \calC, \; \y_0 \in \calD \) such that
    \begin{equation*}
        \norm{\x_0 - \y_0}
        =
        \min_{\x \in \calC, \, \y \in \calD} \norm{\x - \y}
        >
        0
    \end{equation*}
    Let \( \b = \y_0 - \x_0, \; c = \dotp{\b}{\pbrac{\x_0 + \y_0}/2} \).
    We will show that this hyperplane separates \( \calC, \calD \).

    Suppose there exists \( \x' \in \calC \) such that \( \dotp{\b}{\x'} > c \).
    Then,
    \begin{align*}
        &
        0
        <
        2\dotp{\b}{\x' - (\x_0 + \y_0)/2}
        =
        2\dotp{\b}{\pbrac{\x' - \x_0}/2} - 2\dotp{\b}{\pbrac{\y_0 - \x_0}/2}
        =
        2\dotp{\b}{\pbrac{\x' - \x_0}/2} - \norm{\b}^2
        \\
        \implies
        &
        4 \norm{\b}^2 \norm{\pbrac{\x' - \x_0}/2}^2
        >
        4 \norm{\b}^2 \dotp{\b}{\pbrac{\x' - \x_0}/2}
        >
        4 \norm{\b}^4
        \\ &
        4 \norm{\pbrac{\x' - \x_0}/2}^2
        >
        4 \norm{\b}^2
        =
        4 \norm{\y_0 - \x_0}^2
    \end{align*}
    This is a contradiction since \( \x', \x_0 \in \calC, \; \y_0 \in \calD \) and \( \calC, \calD \) are disjoint.
    Thus, \( \dotp{\b}{\x} \leq c, \; \forall \x \in \calC \).
\end{proof}

\section{Farkas' lemma}

\begin{theorem}{Farkas' lemma}{}
    For \( \A \in \R^{m \times n}, \, \b \in \R^m \), exactly one of the following statements is true:
    \begin{enumerate}
        \item \( \exists \x \in \R^n \text{ such that } \A \x = \b \text{ and } \x \geq 0 \).

        \item \( \exists \y \in \R^m \text{ such that } \dotp{\A}{\y} \geq 0 \text{ and } \dotp{\b}{\y} < 0 \).
    \end{enumerate}
\end{theorem}

\begin{proof}
    Suppose both statements are true.
    Then, we have a contradiction since this implies
    \begin{equation*}
        \dotp{\b}{\y}
        =
        \dotp{\pbrac{\A \x}}{\y}
        =
        \dotp{\x}{\dotp{\A}{\y}} \geq 0
    \end{equation*}

    Now, suppose the first statement is false.
    Then, consider the closed convex cone \( \func{C}{\A} \triangleq \set{\A \x \given \x \geq 0} \), which does not contain \( \b \).
    By the separating hyperplane theorem~\pthmref{thm:separating-hyperplane-theorem}, there exists a hyperplane that separates \( \func{C}{\A} \) and \( \b \).
    Thus, there exists \( \y \in \R^m, \; c \in \R \) such that
    \begin{equation*}
        \dotp{\pbrac{\A \x}}{\y}
        =
        \dotp{\x}{\dotp{\A}{\y}}
        \geq c
        > \dotp{\b}{\y},
        \quad \forall \x \geq 0
    \end{equation*}
    Since this holds \( \forall \x \geq 0, \; c > 0, \) we must have \( \dotp{\A}{\y} \geq 0 \),
    Thus, the second statement is true.
\end{proof}

\section{Optimisation standard form}\label{sec:constrained-optimisation-standard-form}

An ""optimisation problem@constrained optimisation problem"" can be put into the following standard form:
\begin{align*}
    \minimize_{\x}
    \quad &
    \func{f}{\x}
    \\ \subjectto \quad &
    \func{c_i}{\x} = 0,
    \quad i \in \calE
    \\ &
    \func{c_i}{\x} \leq 0,
    \quad i \in \calI
\end{align*}
where \( \calE = \set{1, 2, \ldots, p}, \; \calI = \set{p + 1, p + 2, \ldots, p + m}. \)

\begin{itemize}
    \item The function \( f: \R^d \to \R \) is called the \textbf{objective function}.

    \item The functions \( c_i: \R^d \to \R, \; i \in \calI \cup \calE \) are called the \textbf{constraint functions}.

    \item \AP The constraints \( \func{c_i}{\x} = 0, \; i \in \calE \) are called \textbf{""equality constraints""}.

    \item \AP The constraints \( \func{c_i}{\x} \leq 0, \; i \in \calI \) are called \textbf{""inequality constraints""}.

    \item If a point \( \x \in \R^d \) satisfies all the constraints, then it is called a \textbf{""feasible point""}.

    \item If a point \( \x \in \R^d \) violates any of the constraints, then it is called an \textbf{infeasible point}.

    \item The set of all feasible points is called the \textbf{feasible set}.
        \begin{equation*}
            \Omega
            =
            \set{
                \x \in \R^d
                \given
                \func{c_i}{\x} = 0,
                \; i \in \calE
                \quad
                \func{c_i}{\x} \leq 0,
                \; i \in \calI,
            }
        \end{equation*}

    \item An \textbf{optimal point} \( \xstar \) is a feasible point that minimises the objective function, i.e.,\\
        \( \func{f}{\xstar} \leq \func{f}{\x}, \; \forall \x \) feasible.

    \item An \textbf{active constraint} is a constraint that is satisfied with equality at a given feasible point.
        An \textbf{inactive constraint} is a constraint that is satisfied with strict inequality at a given feasible point.
        All equality constraints are always active.
        \( \text{Active constraints} \supseteq \text{Equality constraints} \).

    \item A \textbf{""binding constraint""} is a constraint that is satisfied with equality at a given optimal point.
        A \textbf{non-binding constraint} is a constraint that is satisfied with strict inequality at a given optimal point.
        \( \text{Equality constraints} \subseteq \text{Binding constraints} \subseteq \text{Active constraints} \), i.e., at an optimal point, all active constraints need not be binding, and an equality constraint is always binding.

    \item The \textbf{""active set""} at a feasible point \( \x \) is the set of indices of the active constraints at \( \x \), i.e.,
        \vspace{-0.5em}
        \begin{equation*}
            \func{\calA}{\x}
            \triangleq
            \set{i \given \func{c_i}{\x} = 0, \; i \in \calI}
            \; \cup \;
            \calE
        \end{equation*}

    \item The case \( \calI = \emptyset \), i.e., \( m = 0 \) corresponds to having no inequality constraints, \\
        the case \( \calE = \emptyset \), i.e., \( p = 0 \) corresponds to having no equality constraints, and \\
        the case \( \calI = \calE = \emptyset \), i.e., \( m = p = 0 \) corresponds to an unconstrained optimisation problem.
\end{itemize}

Alternatively, the "constrained optimisation problem" can be written as
\begin{align*}
    \minimize_{\x}
    \quad &
    \func{f}{\x}
    \\ \subjectto \quad &
    \func{g_i}{\x} \leq 0,
    \quad i \in \set{1, 2, \ldots, m}
    \\ &
    \func{h_j}{\x} = 0,
    \quad j \in \set{1, 2, \ldots, p}
\end{align*}

\section{Lagrangian function}

\begin{definition}{Lagrangian function}{}
    The ""\textbf{Lagrangian} / \textbf{Lagrange function}@Lagrange function"" \( \calL: \R^d \times \R^m \times \R^p \to \R \) associated with the "constrained optimisation problem" in~\psecref{sec:constrained-optimisation-standard-form} is defined as
    \vspace{-0.5em}
    \begin{equation*}
        \func{\calL}{\x, \bflambda, \bfmu}
        \triangleq
        \func{f}{\x}
        +
        \sum_{i \in \calI} \lambda_i \, \func{g_i}{\x}
        +
        \sum_{j \in \calE} \mu_j \, \func{h_j}{\x}
    \end{equation*}

    \vspace{-1em}
    where
    \(
        \bflambda
        =
        \begin{bmatrix}
            \lambda_1 &
            \lambda_2 &
            \cdots &
            \lambda_m
        \end{bmatrix}^\top
        \in \R^m
    \)
    and
    \(
        \bfmu
        =
        \begin{bmatrix}
            \mu_{m + 1} &
            \mu_{m + 2} &
            \cdots &
            \mu_{m + p}
        \end{bmatrix}^\top
        \in \R^p
    \).
\end{definition}

\subsection{Lagrange multipliers}

The variables \( \lambda_i, \; i \in \calI \), and \( \mu_j, \; j \in \calE \), are called the \textbf{Lagrange multipliers} / \textbf{dual variables} associated with the inequality and equality constraints respectively.

\section{Karush-Kuhn-Tucker (KKT) conditions}\label{sec:kkt-conditions}

\nointro{KKT conditions}
Consider the "constrained optimisation problem" as in~\psecref{sec:constrained-optimisation-standard-form} where \( f, g_i, h_j \) are differentiable functions.
Let \( \xstar \) be a local minimum and suppose that the gradients of the active constraints at \( \xstar \) are linearly independent.
Then, there exist \( \lambda_i \geq 0, \; i \in \calI, \ \mu_j \in \R, \; j \in \calE \) such that
\begin{align*}
    \func{\nabla_{\x} \calL}{\xstar, \bflambda, \bfmu}
    & =
    \func{\nabla_{\x} f}{\xstar}
    +
    \sum_{i = 1}^{m} \lambda_i \, \func{\nabla_{\x} g_i}{\xstar}
    +
    \sum_{j = 1}^{p} \mu_j \, \func{\nabla_{\x} h_j}{\xstar}
    = \zero
    \tag{stationarity}
    \\ &
    \begin{aligned}
        \func{g_i}{\xstar}
        & \leq 0,
        \quad \forall i \in \calI
        \\
        \func{h_j}{\xstar}
        & = 0,
        \quad \forall j \in \calE
    \end{aligned}
    \tag{primal feasibility}
    \\
    \lambda_i
    & \geq 0,
    \quad \forall i \in \calI
    \tag{dual feasibility}
    \\
    \lambda_i \, \func{g_i}{\xstar}
    & = 0,
    \quad \forall i \in \calI
    \tag{complementary slackness}
\end{align*}

\chapter{Duality}

\section{Primal problem}

Consider the "constrained optimisation problem" as in~\psecref{sec:constrained-optimisation-standard-form}, referred to as the \textbf{primal problem}.
The \textbf{primal variables} are the variables \( \x \in \R^d \) being optimised.

\section{Lagrange dual function}

\begin{definition}{Lagrange dual function}{}
    The \textbf{Lagrange dual function} \( q: \R^m \times \R^p \to \R \) associated with the "constrained optimisation problem" in~\psecref{sec:constrained-optimisation-standard-form} is defined as
    \begin{equation*}
        \func{q}{\bflambda, \bfmu}
        \triangleq
        \min_{\x} \func{\calL}{\x, \bflambda, \bfmu}
    \end{equation*}
\end{definition}

\section{Lagrange dual problem}

The corresponding \textbf{Lagrange dual problem} of the primal problem in~\psecref{sec:constrained-optimisation-standard-form} is given by
\begin{align*}
    \maximize_{\bflambda, \bfmu} \quad &
    \func{q}{\bflambda, \bfmu}
    \\ \subjectto \quad &
    \lambda_i \geq 0,
    \quad i \in \calI
\end{align*}

\section{Weak duality}

\begin{theorem}{Weak duality}{}
    If \( \xhat \) and \( (\hat{\bflambda}, \hat{\bfmu}) \) are any feasible solutions of the primal and dual problems respectively, then
    \vspace{-0.5em}
    \begin{equation*}
        \func{q}{\hat{\bflambda}, \hat{\bfmu}}
        \leq
        \func{f}{\xhat}
    \end{equation*}
\end{theorem}

\begin{proof}
    Since \( \xhat \) is feasible for the primal problem, we have
    \begin{equation*}
        \func{g_i}{\xhat} \leq 0,
        \quad i \in \calI,
        \qquad
        \func{h_j}{\xhat} = 0,
        \quad j \in \calE
    \end{equation*}
    and since \( (\hat{\bflambda}, \hat{\bfmu}) \) is feasible for the dual problem, we have \( \hat{\lambda}_i \geq 0, \; i \in \calI \).
    Thus,
    \begin{equation*}
        \func{q}{\hat{\bflambda}, \hat{\bfmu}}
        =
        \min_{\x} \func{\calL}{\x, \hat{\bflambda}, \hat{\bfmu}}
        \leq
        \func{\calL}{\xhat, \hat{\bflambda}, \hat{\bfmu}}
        =
        \func{f}{\xhat}
        +
        \sum_{i = 1}^{m} \hat{\lambda}_i \, \func{g_i}{\xhat}
        +
        \cancel{ \sum_{j = 1}^{p} \hat{\mu}_j \, \func{h_j}{\xhat} }
        \leq
        \func{f}{\xhat}
    \end{equation*}
\end{proof}

\section{Strong duality}

\begin{theorem}{Strong duality}{}
    For a convex primal problem satisfying the Slater's conditions, if \( \xstar \) and \( (\bflambda^{\star}, \bfmu^{\star}) \) are optimal solutions of the primal and dual problems respectively, then
    \vspace{-0.5em}
    \begin{equation*}
        \func{q}{\bflambda^{\star}, \bfmu^{\star}}
        =
        \func{f}{\xstar}
    \end{equation*}
\end{theorem}

\chapter{Convex programming (CP)}

A \textbf{""convex programming""} problem is a "constrained optimisation problem" where the objective function is a "convex function" and the feasible region is a "convex set".

\paragraph{Abstract form}
\begin{align*}
    \minimize_{\x \in \calC}
    \quad &
    \func{f}{\x}
\end{align*}
where \( f: \calD \subseteq \R^d \to \R \) is a "convex function" and \( \calC \subseteq \calD \) is a "convex set".

\paragraph{Standard form}
\begin{align*}
    \minimize_{\x}
    \quad &
    \func{f}{\x}
    \\ \subjectto \quad &
    \func{g_i}{\x} \leq 0,
    \quad i \in \set{1, 2, \ldots, m}
    \\ &
    \func{h_j}{\x} = 0,
    \quad j \in \set{1, 2, \ldots, p}
\end{align*}
where \( f, \,\, g_i, \, i \in \set{1, 2, \dots, m} \) are "convex functions" and \( h_j, \, j \in \set{1, 2, \dots, p} \) are "affine functions".

For a convex programming problem satisfying the Slater's conditions, if \( \xstar \) and \( \bflambda^{\star} \) are optimal solutions of the primal and dual problems respectively, then the "KKT conditions"~\psecref{sec:kkt-conditions} are necessary and sufficient for optimality.

\section{Linear programming (LP)}

A \textbf{""linear programming""} problem is a "constrained optimisation problem" where the objective function is a "linear function" and the constraints are linear.
\begin{align*}
    \minimize_{\x}
    \quad &
    \dotp{\c}{\x}
    \\ \subjectto \quad &
    \A \x \leq \b
\end{align*}
where \( \c \in \R^d, \; \A \in \R^{m \times d}, \; \b \in \R^m \).

The "Lagrangian function" is given by
\begin{align*}
    \func{\calL}{\x, \bflambda}
    & =
    \dotp{\c}{\x}
    -
    \dotp{\bflambda}{\pbrac{\A \x - \b}}
    \\
    \implies
    \func{\nabla_{\x} \calL}{\x, \bflambda}
    & =
    \c - \dotp{\A}{\bflambda}
\end{align*}

"KKT conditions":
\begin{align*}
    \func{\nabla_{\x} \calL}{\xstar, \bflambda^\ast}
    & =
    \c - \dotp{\A}{\bflambda^\ast}
    = \zero
    \\
    \A \xstar
    &
    \leq \b
    \\
    \bflambda^\ast
    & \geq
    \zero
    \\
    \dotp{\bflambda^\ast}{\pbrac{\A \xstar - \b}}
    & =
    0
\end{align*}

\section{Quadratic programming (QP)}

A \textbf{""quadratic programming""} problem is a "constrained optimisation problem" where the objective function is a quadratic function and the constraints are linear.
\begin{align*}
    \minimize_{\x}
    \quad &
    \half \qf{\x}{\Q} + \dotp{\h}{\x} + c
    \\ \subjectto \quad &
    \A \x \leq \b
\end{align*}
where \( \Q \in \SD, \; \h \in \R^d, \; c \in \R, \; \A \in \R^{m \times d}, \; \b \in \R^m \).

\subsection{Equality-constrained Quadratic Programming (EQP)}\label{sec:eqp}

A ""CEQP"" problem is a "convex@CP" "quadratic programming" problem with only "equality constraints".
\begin{align*}
    \minimize_{\x}
    \quad &
    \half \qf{\x}{\Q} + \dotp{\h}{\x} + c
    \\ \subjectto \quad &
    \A \x = \b
\end{align*}
where \( \Q \in \PSD, \; \h \in \R^d, \; \A \in \R^{m \times d}, \; \b \in \R^m \).

The "Lagrangian function" is given by
\begin{align*}
    \func{\calL}{\x, \bfmu}
    & =
    \half \qf{\x}{\Q} + \dotp{\h}{\x} + c
    -
    \dotp{\bfmu}{\pbrac{\A \x - \b}}
    \\
    \implies
    \func{\nabla_{\x} \calL}{\x, \bfmu}
    & =
    \Q \x + \h - \dotp{\A}{\bfmu}
\end{align*}

"KKT conditions":
\begin{align*}
    \func{\nabla_{\x} \calL}{\xstar, \bfmu^\ast}
    & =
    \Q \xstar + \h - \dotp{\A}{\bfmu^\ast}
    =
    \zero
    \\
    \A \xstar
    & =
    \b
\end{align*}

\subsection{Inequality-constrained Quadratic Programming (IQP)}\label{sec:iqp}

A ""CIQP"" problem is a "convex@CP" "quadratic programming" problem with only "inequality constraints".
\begin{align*}
    \minimize_{\x}
    \quad &
    \half \qf{\x}{\Q} + \dotp{\h}{\x} + c
    \\ \subjectto \quad &
    \A \x \geq \b
\end{align*}
where \( \Q \in \PSD, \; \h \in \R^d, \; \A \in \R^{m \times d}, \; \b \in \R^m \).

The "Lagrangian function" is given by
\begin{align*}
    \func{\calL}{\x, \bflambda}
    & =
    \half \qf{\x}{\Q} + \dotp{\h}{\x} + c
    -
    \dotp{\bflambda}{\pbrac{\A \x - \b}}
    \\
    \implies
    \func{\nabla_{\x} \calL}{\x, \bflambda}
    & =
    \Q \x + \h - \dotp{\A}{\bflambda}
\end{align*}

"KKT conditions":
\begin{align*}
    \func{\nabla_{\x} \calL}{\xstar, \bflambda^\ast}
    & =
    \Q \xstar + \h - \dotp{\A}{\bflambda^\ast}
    =
    \zero
    \\
    \A \xstar
    & \geq
    \b
    \\
    \bflambda^\ast
    & \geq
    \zero
    \\
    \dotp{\bflambda^\ast}{\pbrac{\A \xstar - \b}}
    & =
    0
\end{align*}

\newpage
\chapter{Active set methods}

Active set methods are iterative methods for solving convex constrained optimisation problems.
At each iteration, an estimate of the active set of inequality constraints is maintained and used to solve a simpler optimisation problem with only equality constraints.
The active set is updated based on the solution obtained at each iteration until convergence is achieved.
We only consider "active set" for the inequality constraints, since the equality constraints are always active, i.e.,
\(
    \func{\calA}{\x}
    =
    \set{i \given \func{g_i}{\x} = 0, \; i \in \set{1, 2, \ldots, m}}
\).

\begin{theorem}{Equivalence of CIQP and CEQP at optimality}{}
    The "CEQP" built from the active set of a (strongly convex) "CIQP" at its optimal solution has the same optimal solution as the "CIQP", i.e., given a (strongly convex) "CIQP" with an optimal solution \( (\xstar, \bflambda^\ast) \), the solution to the following CEQP with the active set \( \func{\calA}{\xstar} \) is \( (\xstar, \bfmu^\ast) \), where \( \bfmu^\ast = \bbrac{\bflambda^\ast}_j, \; \forall j \in \func{\calA}{\xstar} \).
    \vspace{-0.5em}
    \begin{equation*}
        \begin{aligned}
            \minimize_{\x}
            \quad &
            \half \qf{\x}{\Q} + \dotp{\h}{\x} + c
            \\ \subjectto \quad &
            \dotp{\a_i}{\x} \geq b_i,
            \quad i \in \set{1, 2, \ldots, m}
        \end{aligned}
        \quad \longleftrightarrow \quad
        \begin{aligned}
            \minimize_{\x}
            \quad &
            \half \qf{\x}{\Q} + \dotp{\h}{\x} + c
            \\ \subjectto \quad &
            \dotp{\a_j}{\x} = b_j,
            \quad j \in \func{\calA}{\xstar}
        \end{aligned}
    \end{equation*}
\end{theorem}

\begin{proof}
    The proof follows from the "KKT conditions" of the "CIQP" and "CEQP".

    Since \( (\xstar, \bflambda^\ast) \) is an optimal solution of the "CIQP", we have from the "KKT conditions" that
    \begin{align*}
        \Q \xstar + \h - \sum_{i = 1}^{m} \bbrac{\bflambda^\ast}_i \, \a_i
        & =
        \zero
        \\
        \dotp{\a_i}{\xstar}
        & \geq
        b_i,
        \quad \forall i \in \set{1, 2, \ldots, m}
        \\
        \bbrac{\bflambda^\ast}_i
        & \geq
        0,
        \quad \forall i \in \set{1, 2, \ldots, m}
        \\
        \bbrac{\bflambda^\ast}_i \, \pbrac{\dotp{\a_i}{\xstar} - b_i}
        & =
        0,
        \quad \forall i \in \set{1, 2, \ldots, m}
    \end{align*}

    The active set of the "CIQP" at \( \xstar \) is given by
    \begin{equation*}
        \func{\calA}{\xstar}
        =
        \set{i \given \dotp{\a_i}{\xstar} = b_i, \; i \in \set{1, 2, \ldots, m}}
    \end{equation*}
    and we can see that \( \forall k \in \set{1, 2, \ldots, m} \setminus \func{\calA}{\xstar}, \; \bbrac{\bflambda^\ast}_k = 0 \) from the complementary slackness condition.
    \begin{align*}
        \implies
        \Q \xstar + \h - \sum_{j \in \func{\calA\,}{\xstar}} \bbrac{\bflambda^\ast}_j \, \a_j
        & =
        \zero
        \\
        \dotp{\a_j}{\xstar}
        =
        b_j,
        \quad &
        \forall j \in \func{\calA}{\xstar}
        \\
        \bbrac{\bflambda^\ast}_j
        \geq 0,
        \quad \forall j \in \func{\calA}{\xstar},
        \quad \text{and} \quad &
        \bbrac{\bflambda^\ast}_k
        = 0,
        \quad \forall k \in \set{1, 2, \ldots, m} \setminus \func{\calA}{\xstar}
    \end{align*}

    For the CEQP constructed from the active set \( \func{\calA}{\xstar} \), let \( (\xhat, \hat{\bfmu}) \) be its optimal solution, and let \( p = \abs{\func{\calA}{\xstar}} \).
    From the "KKT conditions" of the CEQP, we have
    \begin{align*}
        \Q \xhat + \h - \sum_{
            \substack{
                i \in \set{1, 2, \ldots, p}
                \\
                j \in \func{\calA\,}{\xstar}
            }
        } \bbrac{\hat{\bfmu}}_i \, \a_j
        & =
        \zero
        \\
        \dotp{\a_j}{\xhat}
        =
        b_j,
        \quad &
        \forall j \in \func{\calA}{\xstar}
    \end{align*}
    Thereby, the mapping \( \R^p \leftarrow \R_{\geq 0}^m \) defined by \( \bbrac{\hat{\bfmu}}_i \leftarrow \bbrac{\bflambda^\ast}_j, \; \forall j \in \func{\calA}{\xstar} \) and \( \xhat = \xstar \) satisfies the "KKT conditions" of the CEQP;
    \( \therefore (\xstar, \bfmu^\ast) \) is an optimal solution of the CEQP where \( \bfmu^\ast = \bbrac{\bflambda^\ast}_j, \; \forall j \in \func{\calA}{\xstar} \).
\end{proof}

\begin{algorithm}[H]
    \caption{
        Active set method for (strongly convex) "CIQP" using "CEQP"
        \begin{align*}
            \minimize_{\x}
            \quad &
            \half \qf{\x}{\Q} + \dotp{\h}{\x} + c
            \\ \subjectto \quad &
            \dotp{\a_i}{\x} \geq b_i,
            \quad i \in \set{1, 2, \ldots, m}
        \end{align*}
        where \(
            \Q \in \PD
            , \;
            \h \in \R^d
            , \;
            \A
            =
            \begin{bmatrix}
                {\a_1}^\top & {\a_2}^\top & \dots & {\a_m}^\top
            \end{bmatrix}^\top
            \in \R^{m \times d}
            , \;
            \b
            =
            \begin{bmatrix}
                b_1 & b_2 & \dots & b_m
            \end{bmatrix}^\top
            \in \R^m
        \).
    }
    \SetAlgoLined{}
    \KwIn{
        Initial point \( \x^0 \) feasible for the CIQP problem;\\
        Initial (ordered) active set \( \calW_0 \subseteq \func{\calA}{\x^0} \subseteq \set{1, 2, \ldots, m} \);
    }
    \KwOut{
        Minimiser \( \xstar \) and the corresponding Lagrange multipliers \( \bflambda^\ast \) for the CIQP problem\;
    }

    \( k \gets 0 \)\;

    \While{not converged}{
        Solve the search direction subproblem (a CEQP problem);
        \( (\v_k, \bfmu_k) = \operatorname{EQS}(\text{P\( ^k \)}) \)
        \vspace{-0.5em}
        \begin{align*}
            \minimize_{\v}
            \quad &
            \half \qf{\v}{\Q} + \dotp{\pbrac{\Q \x^k + \h}}{\v}
            \tag{P\( ^k \)}
            \\ \subjectto \quad &
            \dotp{\a_i}{\v} = 0,
            \quad i \in \calW_k
        \end{align*}

        \vspace{-0.5em}
        \eIf{\( \v_k = \zero \)}{
            \eIf{\( \bfmu_k \geq \zero \)}{
                \tcp{Optimality conditions met;}

                \( \xstar = \x^k \)\;

                Get \( \bflambda^\ast \in \R^m \) as
                \quad
                \(
                    \bbrac{\bflambda^\ast}_i
                    =
                    \begin{cases}
                        \bbrac{\bfmu_k}_{\func{\operatorname{index}\,}{i, \calW_k}},
                        & i \in \calW_k
                        \\
                        0,
                        & i \in \set{1, 2, \ldots, m} \setminus \calW_k
                    \end{cases}
                \)\;

                \Return{\( \xstar, \, \bflambda^\ast \)\;}
            }{
                \tcp{Relax the most restrictive active constraint;}

                \( \x^{k+1} = \x^k \)\;

                \(
                    \displaystyle
                    \calW_{k+1}
                    =
                    \calW_k
                    \setminus
                    j,
                    \qquad
                    j
                    \in
                    \argmin_{i \in \set{1, 2, \dots, \operatorname{length}(\bfmu_k)}}
                    \bbrac{\bfmu_k}_i
                \)\;
            }
        }{
            \eIf{\( \dotp{\a_i}{\v_k} \geq 0, \; \forall i \in \set{1, 2, \ldots, m} \setminus \calW_k \)}{
                \tcp{All inactive constraints still remain feasible when taking a full step along \( \v_k \);}

                \( \x^{k+1} = \x^k + \v_k \)\;

                \( \calW_{k+1} = \calW_k \)\;
            }{
                Find the step length \( \alpha_k > 0 \) and the blocking constraint indices \( J_k \) as
                \vspace{-0.75em}
                \begin{equation*}
                    \alpha_k, \; J_k
                    =
                    \mathop{\min, \argmin}_{
                        \substack{
                            i \in \set{1, 2, \ldots, m} \setminus \calW_k
                            \\
                            \dotp{\a_i}{\v_k} < 0
                        }
                    }{
                        \frac
                        {b_i - \dotp{\a_i}{\x^k}}
                        {\dotp{\a_i}{\v_k}}
                    }
                \end{equation*}

                \vspace{-1em}
                \( \x^{k+1} = \x^k + \alpha_k \v_k \)\;

                \(
                    \calW_{k+1}
                    = \calW_k \cup \set{j},
                    \quad j \in J_k
                \)\;
            }
        }

        \( k \gets k + 1 \)\;
    }
\end{algorithm}

\newpage
\chapter{Gradient projection method}

\begin{algorithm}[H]
    \caption{
        Gradient projection method for constrained minimisation
    }\label{alg:gradient-projection-method}
    \SetAlgoLined{}
    \KwIn{
        First-order oracle for the objective function \( \func{f}{\x} \);
        Feasible initial point \( \x^0 \in \calC \);
    }
    \KwOut{
        Approximate solution to the constrained minimisation problem \( \displaystyle \argmin_{\x \in \calC} \func{f}{\x} \)\;
    }

    \( k \leftarrow 0 \)\;

    \While{\( \x^k \) is not optimal}{
        Choose a descent direction \( \p^k \) from the set of descent directions
        \begin{equation*}
            \func{\mathcal{DS}}{\x^k}
            =
            \set{\p \in \R^d \given \dotp{\grad{f}{\x^k}}{\p} < 0}
        \end{equation*}

        Choose a step length \( \alpha_k \geq 0 \)\;

        Update the current point: \( \x^{k+1} = \func{P_{\calC}}{\x^k + \alpha_k \p^k} \)\;

        \( k \leftarrow k + 1 \)\;
    }
    \Return{\( \x^k \)\;}
\end{algorithm}

Since \( P_{\calC}: \R^d \to \calC \), we can see that \( \x^k \in \calC, \; \forall k \).

\section{Rate of convergence}

Consider the constant step length rule, i.e., \( \alpha_k = \alpha > 0, \; \forall k \), and the steepest descent direction, i.e., \( \p^k = - \grad{f}{\x^k}, \; \forall k \).
Then, the update step in~\palgref{alg:gradient-projection-method} becomes
\begin{equation*}
    \x^{k+1}
    =
    \func{P_{\calC}}{\x^k - \alpha \, \grad{f}{\x^k}}
\end{equation*}

Let \( f \in \classC^1_L \) be a convex function.
By the first-order condition of convexity, we have
\begin{align*}
    \func{f}{\x}
    & \geq
    \func{f}{\xstar}
    +
    \dotp
    {\grad{f}{\xstar}}
    {\pbrac{\x - \xstar}},
    \quad \forall \x \in \calC
    \\
    \implies
    \func{f}{\xstar}
    & \geq
    \func{f}{\x}
    +
    \dotp
    {\grad{f}{\x}}
    {\pbrac{\xstar - \x}},
    \quad \forall \x \in \calC
    \\
    \implies
    \func{f}{\x}
    & \leq
    \func{f}{\xstar}
    +
    \dotp
    {\grad{f}{\x}}
    {\pbrac{\x - \xstar}},
    \quad \forall \x \in \calC
    \\
    \therefore
    \func{f}{\x^k}
    & \leq
    \func{f}{\xstar}
    +
    \dotp
    {\grad{f}{\x^k}}
    {\pbrac{\x^k - \xstar}},
    \quad \forall \x^k \in \calC
\end{align*}
Now, by the characterisation of projection onto convex sets~\pthmref{thm:projection-characterisation}, i.e.,
\begin{equation*}
    \dotp
    {\pbrac{\func{P_{\calC}}{\z} - \z}}
    {\pbrac{\x - \func{P_{\calC}}{\z}}}
    \geq 0,
    \quad \forall \x \in \calC,
    \; \forall \z \in \R^d
\end{equation*}
with \( \z = \x^k - \alpha \, \grad{f}{\x^k} \), we have \( \func{P_{\calC}}{\z} = \x^{k+1} \), and thus
\begin{equation*}
    \therefore
    \dotp
    {\pbrac{\x^{k+1} - \x^k + \alpha \, \grad{f}{\x^k}}}
    {\pbrac{\x - \x^{k+1}}}
    \geq 0,
    \quad \forall \x \in \calC
\end{equation*}
With \( \x = \x^k \in \calC \), we have
\begin{align*}
    \implies
    \dotp
    {\pbrac{\x^{k+1} - \x^k + \alpha \, \grad{f}{\x^k}}}
    {\pbrac{\x^k - \x^{k+1}}}
    & \geq 0
    \\
    \implies
    \norm{\x^{k+1} - \x^k}_2^2
    & \geq
    \alpha \,
    \dotp
    {\grad{f}{\x^k}}
    {\pbrac{\x^{k+1} - \x^k}}
    \\
    \therefore
    \dotp
    {\grad{f}{\x^k}}
    {\pbrac{\x^{k+1} - \x^k}}
    & \leq
    \frac{1}{\alpha} \, \norm{\x^{k+1} - \x^k}_2^2
\end{align*}
With \( \x = \xstar \in \calC \), we have
\begin{align*}
    \implies
    \dotp
    {\pbrac{\x^{k+1} - \x^k + \alpha \, \grad{f}{\x^k}}}
    {\pbrac{\xstar - \x^{k+1}}}
    & \geq 0
    \\
    \implies
    \alpha \,
    \dotp
    {\grad{f}{\x^k}}
    {\pbrac{\xstar - \x^{k+1}}}
    & \geq
    \dotp
    {\pbrac{\x^k - \x^{k+1}}}
    {\pbrac{\xstar - \x^{k+1}}}
    \\
    \therefore
    \dotp
    {\grad{f}{\x^k}}
    {\pbrac{\x^{k+1} - \xstar}}
    & \leq
    \frac{1}{\alpha} \,
    \dotp
    {\pbrac{\x^k - \x^{k+1}}}
    {\pbrac{\x^{k+1} - \xstar}}
\end{align*}
Since \( f \in \classC^1_L \), we have from~\peqref{eq:lipschitz-gradient-inequality} that
\begin{align*}
    \func{f}{\x^{k+1}}
    & \leq
    \func{f}{\x^k}
    +
    \dotp
    {\grad{f}{\x^k}}
    {\pbrac{\x^{k+1} - \x^k}}
    +
    \frac{L}{2} \, \norm{\x^{k+1} - \x^k}_2^2
    \\ & \leq
    \func{f}{\xstar}
    +
    \dotp
    {\grad{f}{\x^k}}
    {\pbrac{\cancel{\x^k} - \xstar}}
    +
    \dotp
    {\grad{f}{\x^k}}
    {\pbrac{\x^{k+1} - \cancel{\x^k}}}
    +
    \frac{L}{2} \, \norm{\x^{k+1} - \x^k}_2^2
    \\ & =
    \func{f}{\xstar}
    +
    \dotp
    {\grad{f}{\x^k}}
    {\pbrac{\x^{k+1} - \xstar}}
    +
    \frac{L}{2} \, \norm{\x^{k+1} - \x^k}_2^2
    \\ & \leq
    \func{f}{\xstar}
    +
    \frac{1}{\alpha} \,
    \dotp
    {\pbrac{\x^k - \x^{k+1}}}
    {\pbrac{\x^{k+1} - \xstar}}
    +
    \frac{L}{2} \, \norm{\x^{k+1} - \x^k}_2^2
\end{align*}
\begin{equation*}
    \therefore
    \func{f}{\x^{k+1}}
    \leq
    \func{f}{\xstar}
    -
    \frac{1}{\alpha} \,
    \dotp
    {\pbrac{\x^k - \x^{k+1}}}
    {\pbrac{\xstar - \x^{k+1}}}
    +
    \frac{L}{2} \, \norm{\x^{k+1} - \x^k}_2^2
\end{equation*}
Let \( \u_k \triangleq \x^k - \xstar \).
Then, we have that
\(
    \x^{k+1} - \x^k
    =
    \u_{k+1} - \u_k
\), and thus
\begin{equation*}
    \implies
    \func{f}{\x^{k+1}}
    \leq
    \func{f}{\xstar}
    -
    \frac{1}{\alpha} \,
    \dotp
    {\pbrac{\u_k - \u_{k+1}}}
    {\pbrac{- \u_{k+1}}}
    +
    \frac{L}{2} \, \norm{\u_{k+1} - \u_k}_2^2
\end{equation*}
Now, observe that
\begin{align*}
    \norm{\u_k}_2^2
    =
    \norm{\u_{k+1} + \pbrac{\u_k - \u_{k+1}}}_2^2
    & =
    \norm{\u_{k+1}}_2^2
    +
    2 \,
    \dotp
    {\pbrac{\u_k - \u_{k+1}}}
    {\u_{k+1}}
    +
    \norm{\u_k - \u_{k+1}}_2^2
    \\
    \implies
    \dotp
    {\pbrac{\u_k - \u_{k+1}}}
    {\u_{k+1}}
    & =
    \frac{1}{2} \,
    \pbrac{
        \norm{\u_k}_2^2
        -
        \norm{\u_{k+1}}_2^2
        -
        \norm{\u_k - \u_{k+1}}_2^2
    }
\end{align*}
\begin{align*}
    \implies
    \func{f}{\x^{k+1}}
    & \leq
    \func{f}{\xstar}
    +
    \frac{1}{2 \alpha} \,
    \pbrac{
        \norm{\u_k}_2^2
        -
        \norm{\u_{k+1}}_2^2
        -
        \norm{\u_k - \u_{k+1}}_2^2
    }
    +
    \frac{L}{2} \, \norm{\u_k - \u_{k+1}}_2^2
    \\ & =
    \func{f}{\xstar}
    +
    \frac{1}{2 \alpha}
    \pbrac{
        \norm{\u_k}_2^2
        -
        \norm{\u_{k+1}}_2^2
    }
    +
    \half
    \pbrac{
        L
        -
        \frac{1}{\alpha}
    }
    \norm{\u_k - \u_{k+1}}_2^2
\end{align*}
If we choose the step length \( \alpha \) such that \( 0 < \alpha < \frac{1}{L} \), then we have
\begin{align*}
    \implies
    \func{f}{\x^{k+1}}
    & \leq
    \func{f}{\xstar}
    +
    \frac{1}{2 \alpha}
    \pbrac{
        \norm{\u_k}_2^2
        -
        \norm{\u_{k+1}}_2^2
    },
    \qquad
    \alpha \in \pbrac{0, \frac{1}{L}}
    \\
    \implies
    \func{f}{\x^{k+1}} - \func{f}{\xstar}
    & \leq
    \frac{1}{2 \alpha}
    \pbrac{
        \norm{\x^k - \xstar}_2^2
        -
        \norm{\x^{k+1} - \xstar}_2^2
    }
    \\
    \implies
    \sum_{k = 0}^{T - 1}
    \bbrac{
        \func{f}{\x^{k+1}} - \func{f}{\xstar}
    }
    & \leq
    \frac{1}{2 \alpha}
    \pbrac{
        \norm{\x^0 - \xstar}_2^2
        -
        \norm{\x^{T} - \xstar}_2^2
    }
    \leq
    \frac{1}{2 \alpha}
    \norm{\x^0 - \xstar}_2^2
\end{align*}
Let \( \func{g}{\x} \triangleq \func{f}{\x} - \func{f}{\xstar}, \; \forall \x \in \calC \).
We can see that \( g \) is also a convex function since \( f \) is convex.

Now, since \( \sum_{k = 0}^{T - 1} \frac{1}{T} = 1 \), we can apply Jensen's inequality~\psecref{sec:jensens-inequality} on \( \func{g}{\x^{k+1}} \) with weights \( \frac{1}{T}, \; \forall k \in \set{0, 1, \ldots, T - 1} \), and with
\(
    \displaystyle
    \xbar
    \triangleq
    \frac{1}{T}
    \sum_{k = 0}^{T - 1} \x^{k+1}
\), we finally get
\begin{align*}
    \func{g}{\xbar}
    \leq
    \frac{1}{T}
    \sum_{k = 0}^{T - 1}
    \func{g}{\x^{k+1}}
    & =
    \frac{1}{T}
    \sum_{k = 0}^{T - 1}
    \bbrac{
        \func{f}{\x^{k+1}} - \func{f}{\xstar}
    }
    \leq
    \frac{1}{2 \alpha \, T}
    \norm{\x^0 - \xstar}_2^2
    \\
    \therefore
    \func{f}{\xbar} - \func{f}{\xstar}
    & \leq
    \frac{1}{2 \alpha \, T}
    \norm{\x^0 - \xstar}_2^2
    \in
    \bigoh{\frac{1}{T}}
\end{align*}

\( \therefore \) Rate of convergence for the average iterate \( \xbar \) generated by the gradient projection method is sublinear.
