\section{Mathematical preliminaries}

\subsection{Metric space}

A \textbf{metric space} \( (S, d) \) is a set \( S \) together with a \textit{metric/distance function} \( d: S \times S \to \mathbb{R} \) that satisfies the following axioms for all \( x, y, z \in S \):
\begin{itemize}
    \item \( d(x, y) = 0 \iff x = y \)
    \item \textit{Symmetry}: \( d(x, y) = d(y, x) \)
    \item \textit{Triangle inequality}: \( d(x, z) \leq d(x, y) + d(y, z) \)
\end{itemize}

\subsection{Norm}

A \textbf{normed vector space} \( (V, \| \cdot \|) \) is a vector space \( V \) over a field \( \mathbb{F} \) (usually \( \mathbb{R} \) or \( \mathbb{C} \)) equipped with a function \( \| \cdot \|: V \to \mathbb{R} \) that satisfies the following properties for all \( u, v \in V \) and \( a \in \mathbb{F} \):
\begin{itemize}
    \item \textit{Non-negativity}: \( \| v \| \geq 0 \)
    \item \textit{Definiteness}: \( \| v \| = 0 \iff v = 0 \)
    \item \textit{Homogeneity}: \( \| a v \| = |a| \| v \| \)
    \item \textit{Triangle inequality}: \( \| u + v \| \leq \| u \| + \| v \| \)
\end{itemize}

Norm \( \eta: \mathbb{R}^d \to \mathbb{R} \), satisfies
\begin{itemize}
    \item \( \eta(\mathbf{x}) \geq 0 \)
    \item \( \eta(\mathbf{x}) = 0 \iff \mathbf{x} = \mathbf{0} \)
    \item \( \eta(s\mathbf{x}) = |s| \; \eta(\mathbf{x}) \), \quad \( s \in \mathbb{R} \)
    \item \( \eta(\mathbf{x} + \mathbf{y}) \leq \eta(\mathbf{x}) + \eta(\mathbf{y}) \)
\end{itemize}

\subsubsection{\texorpdfstring{\( L_p \) norm}{Lp norm}}
\begin{equation*}
    {\Vert \mathbf{x} \Vert}_p = {\left( \sum_{i=1}^{d} {\vert x_i \vert}^p \right)}^{\frac{1}{p}},
    \quad p \geq 1
\end{equation*}

\paragraph{\( L_2 \) norm (Euclidean norm)}
\begin{equation*}
    {\Vert \mathbf{x} \Vert}_2
    =
    \sqrt{x_1^2 + x_2^2 + \ldots + x_d^2}
    =
    \sqrt{\mathbf{x}^{\top} \mathbf{x}}
\end{equation*}

\subsection{Cauchy-Schwarz inequality}

\begin{equation*}
    \vert \mathbf{x}^{\top} \mathbf{y} \vert \leq {\Vert \mathbf{x} \Vert}_2 \; {\Vert \mathbf{y} \Vert}_2, \quad \mathbf{x}, \mathbf{y} \in \mathbb{R}^d
\end{equation*}

\subsection{Neighborhood}

A \textbf{neighborhood} of a point \( \mathbf{x} \in \mathbb{R}^d \) is an open ball centered at \( \mathbf{x} \) with radius \( r > 0 \), defined as
\begin{equation*}
    B_{r}(\mathbf{x}) = \{ \mathbf{z} \in \mathbb{R}^d \mid \Vert \mathbf{z} - \mathbf{x} \Vert < r \}, \quad r > 0, \ \mathbf{x} \in \mathbb{R}^d
\end{equation*}

\subsection{Interior point}

A point \( \mathbf{x} \in S \) is an \textbf{interior point} of set \( S \subseteq \mathbb{R}^d \) if there exists a neighborhood of \( \mathbf{x} \) that is entirely contained within \( S \), i.e., there exists an \( r > 0 \) such that \( B_{r}(\mathbf{x}) \subseteq S \).

\subsection{Limit point}

A point \( \mathbf{x} \in \mathbb{R}^d \) is a \textbf{limit point} of set \( S \subseteq \mathbb{R}^d \) if every neighborhood of \( \mathbf{x} \) contains at least one point of \( S \) different from \( \mathbf{x} \) itself, i.e., for every \( r > 0 \), there exists a point \( \mathbf{y} \in S \setminus \{ \mathbf{x} \} \) such that \( \mathbf{y} \in B_{r}(\mathbf{x}) \).
\begin{equation*}
    \forall r > 0, \ B_{r}(\mathbf{x}) \cap (S \setminus \{ \mathbf{x} \}) \neq \emptyset
\end{equation*}

Trivially, every interior point of \( S \) is also a limit point of \( S \).

\subsection{Open set}

A set \( S \subseteq \mathbb{R}^d \) is \textbf{open} if every point in \( S \) is an interior point of \( S \).

\subsection{Closed set}

A set \( S \subseteq \mathbb{R}^d \) is \textbf{closed} if it contains all its limit points, i.e., if \( \mathbf{x} \) is a limit point of \( S \), then \( \mathbf{x} \in S \).

\subsection{Bounded set}

A set \( S \subseteq \mathbb{R}^d \) is \textbf{bounded} if there exists \( \mathbf{z} \in \mathbb{R}^d, M \in \mathbb{R} \) such that \( \Vert \mathbf{z} - \mathbf{x} \Vert < M, \ \forall \mathbf{x} \in S \).

\subsection{Infimum}

\subsection{Supremum}

\subsection{Closure}

The \textbf{closure} of a set \( S \subseteq \mathbb{R}^d \) is the smallest closed set containing \( S \), which can be obtained by adding all limit points of \( S \) to \( S \) itself.
\begin{equation*}
    \operatorname{closure}{(S)} = S \cup \{ \text{all limit points of } S \}
\end{equation*}

\subsection{Continuity}

\subsection{Continuous functions}

\subsection{Intermediate value theorem}

\subsection{Little-o notation}

(Landau's notation \cite{apostol1991calculus})
A function \( f: \mathbb{R}^d \to \mathbb{R} \) is said to be in \( o(g(\mathbf{x})) \) as \( \mathbf{x} \to \mathbf{x}_0 \), for some function \( g: \mathbb{R}^d \to \mathbb{R} \), \( g(\mathbf{x}) \neq 0 \) in a neighborhood of \( \mathbf{x}_0 \), if
\begin{equation*}
    \lim_{\mathbf{x} \to \mathbf{x}_0} \frac{f(\mathbf{x})}{g(\mathbf{x})} = 0
\end{equation*}

i.e.,
\begin{equation*}
    \forall \epsilon > 0,
    \exists \delta > 0,
    \text{ s.t. }
    \left\vert \frac{f(\mathbf{x})}{g(\mathbf{x})} \right\vert < \epsilon,
    \quad \forall \mathbf{x} \in B_{\delta}(\mathbf{x}_0) \setminus \{ \mathbf{x}_0 \}
\end{equation*}

\subsubsection{Properties}

\begin{itemize}
    \item If \( f \in o(g) \), then \( c \cdot f \in o(g) \), for any non-zero constant \( c \in \mathbb{R} \).

    \item If \( f \in o(F) \) and \( g \in o(G) \), then \( f \cdot g \in o(F \cdot G) \).

    \item If \( f \in o(h) \) and \( g \in o(h) \), then \( f + g \in o(h) \).

    \item If \( f \in o(g) \) and \( g \in o(h) \), then \( f \in o(h) \).

    \item If \( f(\mathbf{x}) \in o(1) \) as \( \mathbf{x} \to \mathbf{x}_0 \), then \( f(\mathbf{x}) \to 0 \) as \( \mathbf{x} \to \mathbf{x}_0 \).

    \item If \( |f(\mathbf{x})| \leq |h(\mathbf{x})| \) near \( \mathbf{x}_0 \), and \( h \in o(g) \), then \( f \in o(g) \).

    \item If \( f \in o(g) \), and \( \phi: \mathbb{R} \to \mathbb{R} \) is continuous at 0 with \( \phi(0) = 0 \), then \( \phi(f(\mathbf{x})) \in o(\phi(g(\mathbf{x}))) \).

    \item If \( \alpha > \beta > 0 \), then \( \|\mathbf{x} - \mathbf{x}_0\|^\alpha \in o(\|\mathbf{x} - \mathbf{x}_0\|^\beta) \) as \( \mathbf{x} \to \mathbf{x}_0 \).
\end{itemize}

\subsection{Derivative}

The \textbf{derivative} of a function \( f: \mathbb{R} \to \mathbb{R} \) at a point \( x \in \mathbb{R} \) is defined as
\begin{equation*}
    f'(x) = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h}
\end{equation*}

The \textbf{gradient} of a function \( f: \mathbb{R}^d \to \mathbb{R} \) at a point \( \mathbf{x} = \left(x_1, x_2, \ldots, x_d\right)^{\top} \in \mathbb{R}^d \) is defined as
\begin{equation*}
    \nabla f(\mathbf{x}) = \left( \frac{\partial f}{\partial x_1}(\mathbf{x}), \frac{\partial f}{\partial x_2}(\mathbf{x}), \ldots, \frac{\partial f}{\partial x_d}(\mathbf{x}) \right)^{\top}
    \in \mathbb{R}^d
\end{equation*}

The \textbf{Hessian} of a function \( f: \mathbb{R}^d \to \mathbb{R} \) at a point \( \mathbf{x} = \left(x_1, x_2, \ldots, x_d\right)^{\top} \in \mathbb{R}^d \) is defined as
\begin{equation*}
    \nabla^2 f(\mathbf{x}) = \begin{bmatrix}
    \cfrac{\partial^2 f}{\partial x_1^2}(\mathbf{x}) & \cfrac{\partial^2 f}{\partial x_1 \partial x_2}(\mathbf{x}) & \cdots & \cfrac{\partial^2 f}{\partial x_1 \partial x_d}(\mathbf{x}) \\
    \cfrac{\partial^2 f}{\partial x_2 \partial x_1}(\mathbf{x}) & \cfrac{\partial^2 f}{\partial x_2^2}(\mathbf{x}) & \cdots & \cfrac{\partial^2 f}{\partial x_2 \partial x_d}(\mathbf{x}) \\
    \vdots & \vdots & \ddots & \vdots \\
    \cfrac{\partial^2 f}{\partial x_d \partial x_1}(\mathbf{x}) & \cfrac{\partial^2 f}{\partial x_d \partial x_2}(\mathbf{x}) & \cdots & \cfrac{\partial^2 f}{\partial x_d^2}(\mathbf{x})
    \end{bmatrix}
    \in \mathbb{R}^{d \times d}
\end{equation*}

\subsection{Wierstrass extreme value theorem}

\subsection{Taylor's theorem}

\subsubsection{Univariate Taylor's theorem}

\subsubsection{Multivariate Taylor's theorem}

\subsection{Optimisation Methods}

\subsubsection{First-order methods}

Assume \( f \in C^{1} \), and use \( f(\mathbf{x} + \mathbf{p}) = f(\mathbf{x}) + \nabla f(\mathbf{x})^{\top} \mathbf{p} + o(\| \mathbf{p} \|) \).

\subsubsection{Second-order methods}

Assume \( f \in C^{2} \), and use \( f(\mathbf{x} + \mathbf{p}) = f(\mathbf{x}) + \nabla f(\mathbf{x})^{\top} \mathbf{p} + \frac{1}{2} \mathbf{p}^{\top} \nabla^{2} f(\mathbf{x}) \mathbf{p} + o(\| \mathbf{p} \|^2) \).

\subsection{Global minimum}

The point \( \mathbf{x}^* \in \mathbb{R}^d \) is a \textbf{global minimum} of the function \( f: \mathbb{R}^d \to \mathbb{R} \) if
\begin{equation*}
    f(\mathbf{x}^*) \leq f(\mathbf{x}), \quad \forall \mathbf{x} \in \mathbb{R}^d
\end{equation*}

\subsection{Local minimum}

The point \( \mathbf{x}^* \in \mathbb{R}^d \) is a \textbf{local minimum} of the function \( f: \mathbb{R}^d \to \mathbb{R} \) if there exists a \( \delta > 0 \) such that for all \( \mathbf{x} \) in the \( \delta \)-neighborhood of \( \mathbf{x}^* \), we have \( f(\mathbf{x}^*) \leq f(\mathbf{x}) \), i.e.,
\begin{equation*}
    f(\mathbf{x}^*) \leq f(\mathbf{x}), \quad \forall \mathbf{x} \in B_{\delta}(\mathbf{x}^*)
\end{equation*}

\subsection{Necessary and sufficient conditions}

\subsection{Convex functions}
