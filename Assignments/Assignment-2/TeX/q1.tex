\section*{Question 1: Part 1 | Q-Gram-Schmidt \& Conjugate Direction method}

\paragraph{Given:}
\( f: \R^d \to \R \)
\begin{equation*}
    \func{f}{\x}
    =
    \half \qf{\x}{\Q}
    - \dotp{\b}{\x},
    \quad \Q \in \PD, \b \in \R^d
\end{equation*}

\( \Q \)-Gram-Schmidt recursion:
\begin{equation}
    \d_{k+1}
    =
    \p_{k+1}
    - \sum_{i = 0}^{k} \frac{\qf{\p_{k+1}}{\Q}[\d_i]}{\qf{\d_i}{\Q}} \d_i
\end{equation}

\subsection*{(a) \( \Q \)--conjugacy of \( \set{\d_k} \)}

Yes, the vectors produced by the above recursion are \( \Q \)--conjugate, which can be shown by mathematical induction.

\paragraph{Base case:}
\( k = 0 \)
\begin{align*}
    \implies
    \d_1
    & =
    \p_1
    - \frac{\qf{\p_1}{\Q}[\d_0]}{\qf{\d_0}{\Q}} \d_0
    \\
    \implies
    \qf{\d_1}{\Q}[\d_0]
    & =
    \qf{\p_1}{\Q}[\d_0]
    - \frac{\qf{\p_1}{\Q}[\d_0]}{\cancel{\qf{\d_0}{\Q}}} \cancel{\qf{\d_0}{\Q}}
    =
    \qf{\p_1}{\Q}[\d_0]
    - \qf{\p_1}{\Q}[\d_0]
    =
    0
\end{align*}

Thus, \( \d_1 \) is \( \Q \)--conjugate to \( \d_0 \), and the base case holds.

\paragraph{Inductive step:}
Assume that \( \d_i \) is \( \Q \)--conjugate to \( \d_j \) for all \( i, j \leq k \), \( i \neq j \).
We need to show that \( \d_{k+1} \) is \( \Q \)--conjugate to \( \d_j \) for all \( j \leq k \).

For \( j \leq k \), we have as follows
\begin{align*}
    \implies
    \qf{\d_{k+1}}{\Q}[\d_j]
    & =
    \qf{\p_{k+1}}{\Q}[\d_j]
    - \sum_{i = 0}^{k} \frac{\qf{\p_{k+1}}{\Q}[\d_i]}{\qf{\d_i}{\Q}} \qf{\d_i}{\Q}[\d_j]
    \\ & =
    \qf{\p_{k+1}}{\Q}[\d_j]
    - \frac{\qf{\p_{k+1}}{\Q}[\d_j]}{\cancel{\qf{\d_j}{\Q}}} \cancel{\qf{\d_j}{\Q}}
    - \sum_{\substack{i = 0 \\ i \neq j}}^{k} \frac{\qf{\p_{k+1}}{\Q}[\d_i]}{\qf{\d_i}{\Q}} \cancelto{0}{\qf{\d_i}{\Q}[\d_j]}
    \\ & =
    \qf{\p_{k+1}}{\Q}[\d_j]
    - \qf{\p_{k+1}}{\Q}[\d_j]
    - 0
    = 0
\end{align*}

Thus, \( \d_{k+1} \) is \( \Q \)--conjugate to \( \d_j \) for all \( j \leq k \), and the inductive step holds.

Hence, the vectors \( \set{\d_k} \) produced by the above recursion are \( \Q \)--conjugate.

\subsection*{(b) \( \Q = \I \) case}

\( \Q \)--conjugacy reduces to orthogonality for \( \Q = \I \), and the above recursion reduces to the classical Gram-Schmidt orthogonalisation process.
\begin{equation*}
    \d_{k+1}
    =
    \p_{k+1}
    - \sum_{i = 0}^{k} \frac{\dotp{\p_{k+1}}{\d_i}}{\dotp{\d_i}{\d_i}} \d_i
\end{equation*}

\subsection*{(c) Conjugate Direction method}

\( \pbrac[\big]{\alpha_k, \; -\dotp{\grad{f}{\x_k}}{\u_k}, \; \lambda_k} \) for \texttt{CD\_SOLVE}:

\begin{lstlisting}[firstnumber=0]
(0.053245, 1.065069, 20.003149)
(0.012860, 0.258370, 20.090807)
(0.004373, 0.089452, 20.456939)
(0.040859, 0.857295, 20.981996)
(0.036780, 0.837768, 22.777787)
(0.017910, 0.425881, 23.779212)
(0.008054, 0.203932, 25.320880)
(0.099460, 2.725643, 27.404502)
(0.018559, 0.542227, 29.216581)
(0.021784, 0.671296, 30.815420)
(0.008129, 0.265031, 32.602272)
(0.025798, 0.887388, 34.397766)
(0.021509, 0.793338, 36.883692)
(0.024803, 1.056225, 42.584542)
(0.009554, 0.478932, 50.126734)
(0.010861, 0.599837, 55.228448)
(0.017964, 1.075219, 59.852721)
(0.004937, 0.312165, 63.235287)
(0.024913, 1.730925, 69.478934)
(0.007770, 0.625978, 80.562297)
\end{lstlisting}

\section*{Question 1: Part 2 | Conjugate Gradient method}

Number of directions computed: \( \boxed{ m = 14 } \)

\section*{Question 1: Part 3 | Matrix M}

The matrix \( \M \) obtained is as follows:

{\scriptsize \(  \M = \)}
\vspace*{-2em}
\begin{center}
    \adjustbox{max width=\textwidth}{
        \pgfplotstabletypeset[
            col sep=space,
            string type,
            columns/.style={column type={>{$}c<{$}}},
            every head row/.style={output empty row},
        ]{../Codes/M_24233.txt}
    }
\end{center}

In addition, the eigenvalues of \( \M \) are are calculated and found to be:

Eigenvalues of \(  \M \):\@
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
\( \implies \boxed{ \M \approx \I_{14 \times 14} } \)

This shows that the vectors \( \set{\d_k}_{k = 0}^{m-1} \) are \( \A \)--conjugate (upto numerical precision).
\begin{equation*}
    \tilde{\d}_k
    \triangleq
    \frac{\d_k}{\sqrt{\qf{\d_k}{\A}}},
    \qquad \qquad
    M_{ij}
    \triangleq
    \qf{\tilde{\d}_i}{\A}[\tilde{\d}_j],
    \quad
    i, j \in \set{0, \ldots, m - 1}
\end{equation*}
\begin{align*}
    \implies
    M_{ij}
    = 0,
    \quad \forall i \neq j
    & \qquad \iff \qquad
    \qf{\tilde{\d}_i}{\A}[\tilde{\d}_j]
    = 0,
    \quad \forall i \neq j
    \\ & \qquad \qquad \qquad
    \implies
    \qf{\d_i}{\A}[\d_j] = 0,
    \quad \forall i \neq j
    \\
    \implies
    M_{ii}
    = 1,
    \quad \forall i
    & \qquad \iff \qquad
    \qf{\tilde{\d}_i}{\A} = 1,
    \quad \forall i
\end{align*}

\section*{Question 1: Part 4 | \( \A \)--inner product cosine similarity}

List of cosine similarities:
\begin{lstlisting}[firstnumber=0]
0.9999999999999999,
1.0,
1.0,
1.0,
0.9999999999999998,
1.0,
1.0,
1.0000000000000002,
0.9999999999999998,
1.0,
0.9999999999999998,
1.0,
1.0000000000000002,
1.0000000000000002,
\end{lstlisting}

This shows that the vectors \( \d_k \) and \( {\p_k}^{\text{CG}} \) are approximately in the same direction (upto numerical precision) in the \( \A \)--inner product space.
This can be verified from the equality case of Cauchy-Schwarz inequality, and thereby we would have that \( \d_k = c_k \, {\p_k}^{\text{CG}}, \; c_k > 0 \).

Since \( \set{\d_k} \) generated by the \( \Q \)--Gram-Schmidt process are \( \A \)--conjugate, as verified above, the directions \( {\p_k}^{\text{CG}} \) generated by the Conjugate Gradient method are also \( \A \)--conjugate.

In other words, the Conjugate Gradient method implicitly performs a \( \Q \)--Gram-Schmidt process on the directions \( \set{\p_k}^{\text{CG}} \) (while generating them on the fly).

\section*{Question 1: Part 5 | Purpose}

The directions \( \set{\p_k}_{k = 0}^{m-1} \) generated by the Conjugate Gradient method are mutually \( \A \)--conjugate.
