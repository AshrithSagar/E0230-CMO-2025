\section*{Question 3: Part 1 | Newton's method}

\paragraph{Given:}

The rosenbrock function \( f: \R^2 \to \R \)
\begin{equation*}
    \func{f}{\x}
    =
    \pbrac{a - x_1}^2
    +
    b \pbrac{x_2 - x_1^2}^2,
    \qquad
    \x =
    \begin{bmatrix}
        x_1 \\ x_2
    \end{bmatrix}
    \in \R^2,
    \quad a = 1, \; b = 100
\end{equation*}

Initial points \(
    \x_0 \in
    \set{
        \begin{bmatrix}
            2 \\ 2
        \end{bmatrix},
        \begin{bmatrix}
            5 \\ 5
        \end{bmatrix},
        \begin{bmatrix}
            10 \\ -4
        \end{bmatrix},
        \begin{bmatrix}
            50 \\ 60
        \end{bmatrix}
    }
\)

\subsection*{Error norms}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]
    {../Codes/figures/Q3-1a-Newton_error_norms_24233.jpeg}% chktex 8
    \caption{
        Error norm \( \norm{\x_k - \xstar}_2 \) (in log scale) vs iterations \( k \) for \texttt{NEWTON\_SOLVE} with different initial points
    }\label{fig:q3.1a-error-norms}
\end{figure}

\newpage
\subsection*{Contour plots}

\begin{figure}[h!]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]
        {../Codes/figures/Q3-1b-Newton_path_1_24233.jpeg}% chktex 8
        \caption{
            Initial point
            \(
                \x_0 =
                \begin{bmatrix}
                    2 \\ 2
                \end{bmatrix}
            \)
        }\label{fig:q3.1b-contour-1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]
        {../Codes/figures/Q3-1b-Newton_path_2_24233.jpeg}% chktex 8
        \caption{
            Initial point
            \(
                \x_0 =
                \begin{bmatrix}
                    5 \\ 5
                \end{bmatrix}
            \)
        }\label{fig:q3.1b-contour-2}
    \end{subfigure}
    \vskip\baselineskip{}
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]
        {../Codes/figures/Q3-1b-Newton_path_3_24233.jpeg}% chktex 8
        \caption{
            Initial point
            \(
                \x_0 =
                \begin{bmatrix}
                    10 \\ -4
                \end{bmatrix}
            \)
        }\label{fig:q3.1b-contour-3}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]
        {../Codes/figures/Q3-1b-Newton_path_4_24233.jpeg}% chktex 8
        \caption{
            Initial point
            \(
                \x_0 =
                \begin{bmatrix}
                    50 \\ 60
                \end{bmatrix}
            \)
        }\label{fig:q3.1b-contour-4}
    \end{subfigure}
    \caption{
        Contour plots of the rosenbrock function with paths taken by \texttt{NEWTON\_SOLVE} from different initial points clipped in the region \( [-10, 10] \times [-10, 10] \)
    }\label{fig:q3.1b-contours}
\end{figure}

\newpage
\section*{Question 3: Part 2 | Analysis}

\paragraph{Which starting points lead to rapid convergence to \( \xstar \)?}
Particularly, the initial points \( \x_0 =
    \begin{bmatrix} 2 & 2
\end{bmatrix}^\top \) and \( \x_0 =
    \begin{bmatrix} 5 & 5
\end{bmatrix}^\top \) lead to rapid convergence, as is the case for Newton's method in general when started sufficiently close to the minimizer, in the Newton's region.

\paragraph{Which ones fail or diverge?}
None of the initial points tried lead to failure or divergence of the method.

\paragraph{Briefly explain why the starting point plays such a crucial role in Newton's method.}
The starting point plays a crucial role in Newton's method because the method relies on local approximations of the function using its gradient and Hessian at the current point.
If the starting point is close to the minimizer, the local quadratic approximation is accurate, leading to rapid convergence.
Additionally, the Hessian must be positive definite at the current point for the Newton step to be a descent direction; if the starting point is in a region where the Hessian is not positive definite, the method may fail to converge.

\paragraph{Result interpretation}
As can be seen from the error norms graph~(\autoref{fig:q3.1a-error-norms}), Newton's method converges in very few iterations (4--5) for all initial points tried.

The contour plots~(\autoref{fig:q3.1b-contours}) show that the method takes large steps towards the minimizer \( \xstar \) in each iteration for starting points far away from the minimizer~(\autoref{fig:q3.1b-contour-2},~\ref{fig:q3.1b-contour-3},~\ref{fig:q3.1b-contour-4}).
As in turns out, all of the different initial points tried converge to the same minimizer
\(
    \xstar =
    \begin{bmatrix}
        1 & 1
    \end{bmatrix}^\top
\), which is the unique global minimizer of the rosenbrock function.
