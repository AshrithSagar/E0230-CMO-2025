\documentclass[twoside,11pt]{article}

% Any additional packages needed should be included after jmlr2e.
% Note that jmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.jmlr.org/format/natbib.pdf

% Available options for package jmlr2e are:
%
%   - abbrvbib : use abbrvnat for the bibliography style
%   - nohyperref : do not load the hyperref package
%   - preprint : remove JMLR specific information from the template,
%         useful for example for posting to preprint servers.
%
% Example of using the package with custom options:
%
% \usepackage[abbrvbib, preprint]{jmlr2e}

\usepackage[preprint]{jmlr2e}

\usepackage{amsmath}

% Definitions of handy macros can go here

\newcommand{\dataset}{{\cal D}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}

\newcommand{\argmin}{\mathop{\mathrm{argmin}}}

% Heading arguments are {volume}{year}{pages}{date submitted}{date published}{paper id}{author-full-names}

\firstpageno{1}
\setlength{\parindent}{0cm}

\begin{document}

\title{CMO Assignment 0}

\author{\name Ashrith Sagar Yedlapalli \email ashrithy@iisc.ac.in \\
       \addr 24233}

\maketitle

\section*{Question 1}

We want to find the solution of the unconstrained optimisation problem with \( f: \mathbb{R} \to \mathbb{R} \),
\begin{equation*}
       x^\ast = \argmin_{x \in \mathbb{R}} f(x)
\end{equation*}
where \( f \) is differentiable and accessible only via a \emph{first-order oracle} \( \mathcal{O}_{\text{SRN}}(x) = \left( f(x), f'(x) \right) \).

From \citet[Section 1.2.1]{Nesterov2004}, we know that when \( f \) is differentiable at \( \bar{x} \in \mathbb{R} \), then for any \( y \in \mathbb{R} \), we have
\begin{equation*}
       f(y) = f(\bar{x}) + f'\!(\bar{x}) \, (y - \bar{x}) + o(\vert y - \bar{x} \vert),
\end{equation*}
where \( o(r): \mathbb{R} \to \mathbb{R} \) is a function such that \( \lim_{r \to 0} \frac{1}{r} o(r) = 0 \) and \( o(0) = 0 \).
Using this, we can see that, as mentioned in \citet[Section 1.2.1, Lemma 1.2.1]{Nesterov2004} that the direction \( -f'(\bar{x}) \) is the direction of the fastest local decrease of \( f \) at point \( \bar{x} \).

\paragraph{Iterative algorithm template.} \citep[Section 1.1.2]{Nesterov2004}
\begin{enumerate}
       \item Start with an initial guess \( x^{(0)} \in \mathbb{R} \).
       \item For \( k = 0, 1, \ldots \)
       \begin{enumerate}
              \item Query the oracle \( \mathcal{O}_{\text{SRN}}(x^{(k)}) \) to get \( f\big(x^{(k)}\big) \) and \( f'\big(x^{(k)}\big) \).
              \item If \( \vert f'\big(x^{(k+1)}\big) \vert < \epsilon \) for some small \( \epsilon > 0 \), then
                     stop and verify \( x^{(k+1)} \).
              \item Otherwise, apply the algorithm step \( \operatorname{ALGO} \) to update the guess:
                     \begin{equation*}
                            x^{(k+1)} = \operatorname{ALGO}\big( x^{(k)} \big)
                     \end{equation*}
       \end{enumerate}
\end{enumerate}
The above has been implemented as a Python class \texttt{IterativeOptimiser} in the code.

\paragraph{Gradient Descent.}
Gradient descent is a \textit{first-order iterative} optimisation algorithm for finding a local minimum of a differentiable function.
Starting from an initial guess \( x^{(0)} \in \mathbb{R} \), the update rule is
\begin{equation*}
       x^{(k+1)} = x^{(k)} - \eta \, f'\big(x^{(k)}\big)
\end{equation*}
where \( \eta > 0 \) is the learning rate.
The motivation is that \( -f'(x) \) points in the direction of steepest local decrease of \( f \), so repeated updates move \( x \) towards a (local) minimum.

\paragraph{Backtracking Line Search.}
Backtracking line search is a technique to adaptively choose the step size \( \eta \) in gradient descent.
It starts with an initial learning rate \( \eta_0 > 0 \) and iteratively reduces it by a factor \( \beta \in (0, 1) \) until the Goldstein-Armijo rule \citep[Section 1.2.3]{Nesterov2004} is satisfied:
\begin{align*}
       \alpha \cdot f'(x^{(k)}) \cdot (x^{(k)} - x^{(k+1)}) & \leq f(x^{(k)}) - f(x^{(k+1)}), \\
       \beta \cdot f'(x^{(k)}) \cdot (x^{(k)} - x^{(k+1)}) & \geq f(x^{(k)}) - f(x^{(k+1)}),
\end{align*}
where \( 0 < \alpha < \beta < 1 \) are some fixed parameters.
The algorithm is as follows:
\begin{enumerate}
       \item Set \( \eta = \eta_0 \).
       \item While the Armijo condition is not satisfied, reduce \( \eta \) by multiplying it by \( \beta \).
       \item Update \( x^{(k+1)} = x^{(k)} - \eta \, f'\big(x^{(k)}\big) \), just as in gradient descent.
\end{enumerate}

In a way, this algorithm is just a more sophisticated version of gradient descent, where the step size is adaptively chosen according to the Goldstein-Armijo rule, whereas in gradient descent previously, the step size is fixed.

\paragraph{BFGS (general form).}
The Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm is a quasi-Newton method that approximates the inverse Hessian matrix \( \mathbf{H}_k \) of the objective function \( f: \mathbb{R}^n \to \mathbb{R} \) \citep{cmo11}, through changes in the Hessian instead of modelling the changes in the inverse Hessian.
The update step is
\begin{equation*}
       \mathbf{x}^{(k+1)} = \mathbf{x}^{(k)} - \mathbf{H}_k \, \nabla f\big(\mathbf{x}^{(k)}\big)
\end{equation*}
where \( \mathbf{H}_k \) is updated at each iteration using curvature information from successive iterates:
\begin{equation*}
       \mathbf{H}_{k+1}
       =
       \left[ \mathbf{I} - \frac{\mathbf{s}_k \mathbf{y}_k^\top}{\mathbf{y}_k^\top \mathbf{s}_k} \right]
       \mathbf{H}_k
       \left[ \mathbf{I} - \frac{\mathbf{y}_k \mathbf{s}_k^\top}{\mathbf{y}_k^\top \mathbf{s}_k} \right]
       + \frac{\mathbf{s}_k \mathbf{s}_k^\top}{\mathbf{y}_k^\top \mathbf{s}_k},
       \quad
       \text{where}
       \quad
       \begin{aligned}
              \mathbf{s}_k & = \mathbf{x}^{(k+1)} - \mathbf{x}^{(k)},
              \\
              \mathbf{y}_k & = \nabla f(\mathbf{x}^{(k+1)}) - \nabla f\big(\mathbf{x}^{(k)}\big)
       \end{aligned}
\end{equation*}

\paragraph{BFGS in 1D.}
For the one-dimensional case (\( n = 1 \)), all vectors and matrices reduce to scalars.
Then the BFGS update simplifies drastically to
\begin{equation*}
       H_{k+1} = \frac{s_k}{y_k},
       \qquad
       s_k = x^{(k+1)} - x^{(k)},
       \qquad
       y_k = f'(x^{(k+1)}) - f'\big(x^{(k)}\big)
\end{equation*}
and the step becomes
\begin{equation*}
       x^{(k+1)} = x^{(k)} - H_{k+1}\, f'\big(x^{(k)}\big)
       \implies
       \boxed{
       x^{(k+1)} = x^{(k)} - \frac{x^{(k+1)} - x^{(k)}}{f'(x^{(k+1)}) - f'\big(x^{(k)}\big)} \, f'\big(x^{(k)}\big)
       }
\end{equation*}
Thus, in 1D, BFGS becomes similar to the \emph{secant method applied to the derivative} \( f'(x) \).

Amongst the above algorithms, the BFGS is the fastest and most efficient in addition to being robust to the choice of initial guess and learning rate.
The analytical complexity \citep[Section 1.1.2]{Nesterov2004}, i.e., the number of oracle queries to solve the problem upto an accuracy of \( \epsilon \), is the least amongst the rest.

\vspace{1em}
The value of \( x^\ast \) found is \( \boxed{\mathbf{0.250000}} \) and the corresponding value of \( f(x^\ast) \) is \( \boxed{\mathbf{0.123400}} \).

\vskip 0.2in
\bibliography{refs}

\end{document}
