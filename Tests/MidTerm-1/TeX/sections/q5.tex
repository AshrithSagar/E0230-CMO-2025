\section*{Question 5}

Let \( \xstar \) be the global minimum of a convex function \( f \in \classC^1_L \).
Use \texttt{DESCENT} with \( \u^k = -\nabla f\left(\x^k\right) \).
Let \( \alpha_{k} = \frac{\beta}{L} \) where \( 0<\beta<2 \).
Answer the following with justification.
\begin{enumerate}[label= (\alph*)]
    \item Do all iterates lie in \( S = \left\{ \x \mid\left\Vert\x-\xstar\right\Vert \leq\left\Vert\x^0-\xstar\right\Vert \right\} \)?

    \item Do the iterates obey the sufficient decrease lemma?

    \item Find the minimum number of iterations required to ensure a point whose function value is at most \( .01 \) more than the value of global minimum value.
        Assume that \( \left\Vert\x^0-\xstar\right\Vert = 1 \).
\end{enumerate}

\subsection*{Solution}

\paragraph{Given:}
\begin{equation*}
    f \in \classC^1_L,
    \quad
    \xstar = \argmin_{\x} \func{f}{\x},
    \quad
    \u^k = -\grad{f}{\x^k},
    \quad
    \alpha_{k} = \frac{\beta}{L}, \; 0 < \beta < 2
\end{equation*}

\subsubsection*{(a)}

Since \( f \in \classC^1_L \), we have
\begin{align*}
    \norm{\grad{f}{\x} - \grad{f}{\y}}
    & \leq
    L \, \norm{\x - \y},
    \quad \forall \x, \y \in \R^d
    \\
    \implies
    \norm{\grad{f}{\x}}
    & =
    \norm{\grad{f}{\x} - \grad{f}{\xstar}}
    \leq
    L \, \norm{\x - \xstar},
    \quad \forall \x \in \R^d
    \\
    \implies
    \norm{\grad{f}{\x}}^2
    & \leq
    L^2 \, \norm{\x - \xstar}^2,
    \quad \forall \x \in \R^d
\end{align*}
Now, by Cauchy-Schwarz inequality, we have
\begin{align*}
    \abs{\dotp{\x}{\y}}
    & \leq
    \norm{\x} \, \norm{\y},
    \quad \forall \x, \y \in \R^d
    \\
    \implies
    \abs{\dotp{\left( \grad{f}{\x} - \grad{f}{\y} \right)}{(\x - \y)}}
    & \leq
    \norm{\grad{f}{\x} - \grad{f}{\y}} \, \norm{\x - \y},
    \quad \forall \x, \y \in \R^d
    \\ & \leq
    L \, \norm{\x - \y}^2,
    \quad \forall \x, \y \in \R^d
    \\
    \implies
    \abs{\dotp{\grad{f}{\x}}{(\x - \xstar)}}
    & \leq
    L \, \norm{\x - \xstar}^2,
    \quad \forall \x \in \R^d
\end{align*}
Now, we can see that
\begin{align*}
    \x^{k+1}
    & =
    \x^k + \alpha_k \u^k
    =
    \x^k - \frac{\beta}{L} \grad{f}{\x^k}
    \\
    \implies
    \x^{k+1} - \xstar
    & =
    \x^k - \xstar - \frac{\beta}{L} \grad{f}{\x^k}
    \\
    \norm{\x^{k+1} - \xstar}^2
    & =
    \norm{\big( \x^k - \xstar \big) - \frac{\beta}{L} \grad{f}{\x^k}}^2
    \\ & =
    \norm{\x^k - \xstar}^2
    + \norm{\frac{\beta}{L} \grad{f}{\x^k}}^2
    - 2 \frac{\beta}{L} \dotp{\grad{f}{\x^k}}{(\x^k - \xstar)}
    \\ & \leq
    \norm{\x^k - \xstar}^2
    + \frac{\beta^2}{\cancel{L^2}} \cancel{L^2} \norm{\x^k - \xstar}^2
    - 2 \frac{\beta}{\cancel{L}} \cancel{L} \norm{\x^k - \xstar}^2
    \\ & =
    (1 + \beta^2 - 2\beta) \, \norm{\x^k - \xstar}^2
    =
    {(1 - \beta)}^2 \, \norm{\x^k - \xstar}^2
\end{align*}

Since \( 0 < \beta < 2 \implies -2 < -\beta < 0 \implies -1 < 1 - \beta < 1 \implies {(1 - \beta)}^2 < 1 \), we have
\begin{equation*}
    \norm{\x^{k+1} - \xstar}^2
    < \norm{\x^k - \xstar}^2,
    \quad \forall k \geq 0
\end{equation*}

By induction, we can see that all the iterates lie in the set \( S = \set{ \x \;\middle|\; \norm{\x - \xstar} \leq \norm{\x^0 - \xstar} } \).

\subsubsection*{(b)}

Sufficient decrease lemma states
\begin{equation*}
    \frac{\func{f}{\x^k} - \func{f}{\x^{k+1}}}{\norm{\grad{f}{\x^k}}^2}
    \geq
    R_k
    \geq
    R
    > 0
\end{equation*}

Since \( f \in \classC^1_L \), we have
\begin{align*}
    \func{f}{\y}
    & \leq
    \func{f}{\x}
    + \dotp{\grad{f}{\x}}{(\y - \x)}
    + \frac{L}{2} \, \norm{\y - \x}^2,
    \quad \forall \x, \y \in \R^d
    \\
    \implies
    \func{f}{\x^{k+1}}
    & \leq
    \func{f}{\x^k}
    + \dotp{\grad{f}{\x^k}}{\big( \x^{k+1} - \x^k \big)}
    + \frac{L}{2} \, \norm{\x^{k+1} - \x^k}^2
    \\
    \implies
    \func{f}{\x^k} - \func{f}{\x^{k+1}}
    & \geq
    - \dotp{\grad{f}{\x^k}}{\big( \x^{k+1} - \x^k \big)}
    - \frac{L}{2} \, \norm{\x^{k+1} - \x^k}^2
    \\ & =
    \frac{\beta}{L} \norm{\grad{f}{\x^k}}^2
    - \frac{\cancel{L}}{2} \frac{\beta^2}{L^{\cancel{2}}} \, \norm{\grad{f}{\x^k}}^2
    \\
    \implies
    \frac{\func{f}{\x^k} - \func{f}{\x^{k+1}}}{\norm{\grad{f}{\x^k}}^2}
    & \geq
    \frac{\beta}{L}
    - \frac{\beta^2}{2 L}
    =
    \frac{\beta (2 - \beta)}{2 L}
    \\
    \implies
    &
    R_k
    \triangleq
    \boxed{
        R
        \triangleq
        \frac{\beta (2 - \beta)}{2 L}
    }
    > 0,
    \quad \forall k \geq 0
\end{align*}

Thus, the iterates obey the sufficient decrease lemma.

\subsubsection*{(c)}

We want to find a minimum \( k \) such that
\begin{equation*}
    \func{f}{\x^k}
    \leq
    \func{f}{\xstar}
    + 0.01
\end{equation*}
given that \( \norm{\x^0 - \xstar} = 1 \).

Now, since \( f \in \classC^1_L \), we have
\begin{align*}
    \func{f}{\y}
    & \leq
    \func{f}{\x}
    + \dotp{\grad{f}{\x}}{(\y - \x)}
    + \frac{L}{2} \, \norm{\y - \x}^2,
    \quad \forall \x, \y \in \R^d
    \\
    \implies
    \func{f}{\x^k}
    & \leq
    \func{f}{\xstar}
    + \frac{L}{2} \, \norm{\x^k - \xstar}^2
    \\
    \implies
    \func{f}{\x^k} - \func{f}{\xstar}
    & \leq
    \frac{L}{2} \, \norm{\x^k - \xstar}^2
    \leq
    \frac{L}{2} {(1 - \beta)}^{2k} \, \norm{\x^0 - \xstar}^2
    =
    \frac{L}{2} {(1 - \beta)}^{2k}
    \\
    \text{Now, if }
    \frac{L}{2} {(1 - \beta)}^{2k}
    & \leq
    0.01,
    \quad \text{then }
    \func{f}{\x^k}
    \leq
    \func{f}{\xstar}
    + 0.01
    \\
    \implies
    {(1 - \beta)}^{2k}
    & \leq
    \frac{0.02}{L}
    \implies
    2k \ln{\abs{1 - \beta}}
    \leq
    \ln{\frac{0.02}{L}}
    =
    -\ln{50} - \ln{L}
    \\
    \implies
    k
    & \geq
    \boxed{
        \frac{-\ln{50} - \ln{L}}{2 \ln{\abs{1 - \beta}}}
    },
    \quad \because \ln{\abs{1 - \beta}} < 0
\end{align*}

Since \( f \) is convex, we have
\begin{align*}
    \func{f}{\y}
    & \geq
    \func{f}{\x}
    + \dotp{\grad{f}{\x}}{(\y - \x)},
    \quad \forall \x, \y \in \R^d
    \\
    \implies
    \func{f}{\xstar}
    & \geq
    \func{f}{\x^k}
    + \dotp{\grad{f}{\x^k}}{(\xstar - \x^k)}
    \\
    \implies
    \func{f}{\x^k} - \func{f}{\xstar}
    & \leq
    -\dotp{\grad{f}{\x^k}}{(\xstar - \x^k)}
    =
    \dotp{\grad{f}{\x^k}}{(\x^k - \xstar)}
    \\ & \leq
    \abs{\dotp{\grad{f}{\x^k}}{(\x^k - \xstar)}}
    \leq
    \norm{\grad{f}{\x^k}} \, \norm{\x^k - \xstar}
    \\
    \because
    \norm{\x^k - \xstar}
    & \leq
    \norm{\x^0 - \xstar}
    = 1,
    \quad \forall k \geq 0
    \\
    \implies
    &
    \boxed{
        \func{f}{\x^k} - \func{f}{\xstar}
        \leq
        \norm{\grad{f}{\x^k}},
        \quad \forall k \geq 0
    }
    \\
    \because
    \frac{\func{f}{\x^k} - \func{f}{\x^{k+1}}}{\norm{\grad{f}{\x^k}}^2}
    & \geq
    R
    > 0,
    \quad \forall k \geq 0
    \\
    \implies
    \norm{\grad{f}{\x^k}}^2
    & \leq
    \frac{\func{f}{\x^k} - \func{f}{\x^{k+1}}}{R},
    \quad \forall k \geq 0
    \\
    \implies
    \func{f}{\x^k} - \func{f}{\x^{k+1}}
    & \geq
    R {\left( \func{f}{\x^k} - \func{f}{\xstar} \right)}^2,
    \quad \forall k \geq 0
\end{align*}

Define \( \delta_k \triangleq \func{f}{\x^k} - \func{f}{\xstar} \geq 0 \).
Then, we have
\begin{align*}
    \implies
    \delta_k - \delta_{k+1}
    & \geq
    R \, \delta_k^2,
    \quad \forall k \geq 0
    \\
    \implies
    \delta_{k+1}
    & \leq
    \delta_k - R \, \delta_k^2
    =
    \delta_k (1 - R \, \delta_k)
    \\
    \implies
    \frac{1}{\delta_{k+1}}
    & \geq
    \frac{1}{\delta_k (1 - R \, \delta_k)}
    =
    \frac{1}{\delta_k} \cdot \frac{1}{1 - R \, \delta_k}
    \\
    \because
    \sum_{i = 0}^{\infty} x^i
    =
    \frac{1}{1 - x}
    & \geq
    1 + x,
    \quad \forall x \in \R, \; \abs{x} < 1
    \\
    \implies
    \frac{1}{1 - R \, \delta_k}
    & \geq
    1 + R \, \delta_k,
    \quad \text{if } R \, \delta_k < 1
    \\
    \implies
    \frac{1}{\delta_{k+1}}
    & \geq
    \frac{1}{\delta_k} (1 + R \, \delta_k)
    =
    \frac{1}{\delta_k} + R,
    \quad \text{if } R \, \delta_k < 1
    \\
    \implies
    \frac{1}{\delta_k}
    & \geq
    \frac{1}{\delta_0} + k R
    \geq
    k R,
    \quad \text{if } R \, \delta_i < 1,
    \; \forall i < k
    \\
    \implies
    \delta_k
    & \leq
    \frac{1}{k R},
    \quad \text{if } R \, \delta_i < 1,
    \; \forall i < k
    \\
    \text{Now, }
    \because
    \delta_0
    =
    \func{f}{\x^0} - \func{f}{\xstar}
    & \leq
    \frac{L}{2} \, \norm{\x^0 - \xstar}^2
    =
    \frac{L}{2}
    = \frac{1}{R} \cdot \frac{\beta (2 - \beta)}{4}
    < \frac{1}{R},
    \quad \because 0 < \beta < 2
    \\
    \implies
    R \, \delta_0
    & < 1
    \\
    \implies
    R \, \delta_i
    & < 1,
    \quad \forall i < k
    \\
    \implies
    &
    \boxed{
        \delta_k
        \leq
        \frac{1}{k R},
        \quad \forall k \geq 1
    }
    \\
    \text{Thus, if }
    \frac{1}{k R}
    & \leq
    0.01,
    \quad \text{then }
    \func{f}{\x^k}
    \leq
    \func{f}{\xstar}
    + 0.01
\end{align*}
\begin{equation*}
    \implies
    k
    \geq
    \frac{1}{0.01 R}
    =
    \frac{100}{R}
    =
    \boxed{
        \frac{200 L}{\beta (2 - \beta)}
    }
\end{equation*}
